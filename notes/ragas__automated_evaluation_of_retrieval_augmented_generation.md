---
title: "Ragas: Automated Evaluation of Retrieval Augmented Generation"
authors: "Shahul Es, Jithin James, Luis Espinosa-Anke, Steven Schockaert"
year: 2025
tags: ["Computer Science - Computation and Language", "Evaluation"]
link: "http://arxiv.org/abs/2309.15217"
---


# üöÄ TL;DR


Framework ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏• RAG ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏â‡∏•‡∏¢


## üí° Key Insight / "The Aha! Moment"


‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏â‡∏•‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡∏±‡∏î‡∏ú‡∏• RAG ‡πÑ‡∏î‡πâ‡∏¢‡∏≤‡∏Å ‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡πÉ‡∏ô 3 ‡∏™‡πà‡∏ß‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ LLM - Faithfulness, Answer Relevance, Context Relevance ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏°‡∏≠‡∏á‡∏≠‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡πÉ‡∏ô‡∏ö‡∏Å‡∏û‡∏£‡πà‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà


## üßê Problem Statement

- ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏∞‡∏ß‡∏±‡∏î‡∏ú‡∏• RAG ‡∏¢‡∏±‡∏á‡πÑ‡∏á
- ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏â‡∏•‡∏¢ ‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏ä‡πâ‡πÅ‡∏£‡∏á‡∏Ñ‡∏ô

## üõ†Ô∏è Methodology (The "How")

- **Architecture:** [‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏î 3 ‡∏Ñ‡πà‡∏≤ ‡πÉ‡∏ä‡πâ LLM ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏±‡πâ‡∏ô (GPT-4) ‡πÅ‡∏•‡∏∞ embedding ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏±‡πâ‡∏ô (text-embedding-ada-002)
- **Data:** 50 Wikipedia pages ‡∏õ‡∏µ 2022 ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏õ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏ó‡∏£‡∏ô‡∏ñ‡∏∂‡∏á (knowledge cutoff)
- **Scoring:**
    - ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ
        - ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
        - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° (‡∏ö‡∏£‡∏¥‡∏ö‡∏ó)
        - ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
    - Faithfulness - ‡πÉ‡∏´‡πâ LLM ‡πÅ‡∏ï‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏¢‡πà‡∏≠‡∏¢‡πÜ ‡πÄ‡∏≠‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡πà‡∏≠‡∏¢‡πÜ‡πÑ‡∏õ‡πÑ‡∏•‡πà‡πÄ‡∏ä‡πá‡∏Ñ‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ß‡πà‡∏≤‡∏ï‡∏£‡∏á‡∏°‡∏±‡πâ‡∏¢ ‡∏Å‡∏µ‡πà‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå
    - Answer Relevance - ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡πÉ‡∏´‡πâ LLM ‡πÄ‡∏î‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏≤
    - Context Relevance - ‡πÉ‡∏´‡πâ LLM ‡∏Ñ‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏µ‡πà‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
- **Experiment:**
    - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wikipedia
    - ‡∏à‡∏±‡∏î‡πÅ‡∏Ç‡πà‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå vs AI ‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô‡∏ß‡πà‡∏≤‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏π‡∏Å ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå
    - Faithfulness - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á‡πÜ vs ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏õ‡∏•‡∏≠‡∏°‡πÜ
    - Answer Relevance - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏£‡∏¥‡∏á‡πÜ  vs ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
    - Context Relevance - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏ô‡∏∑‡πâ‡∏≠ vs ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏õ‡∏ô‡∏Ç‡∏¢‡∏∞
    - ‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡∏Ñ‡∏π‡πà‡πÑ‡∏´‡∏ô‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà AI ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏î‡∏≤
    - AI ‡∏°‡∏µ‡∏™‡∏≤‡∏°‡∏ï‡∏±‡∏ß (RAGAS framework, GPT score, GPT ranking)

## üìä Results & Evaluation

- **Baselines:** GPT
- **Metrics:** ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á RAGAS ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏™‡∏∏‡∏î

## üí≠ My Critique

- **Strengths:**
    - Framework ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÑ‡∏î‡πâ
- **Weaknesses/Limitations:**
    - ‡∏ñ‡πâ‡∏≤ AI ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏Å‡πà‡∏á‡∏û‡∏≠ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ baseline ‡∏Ñ‡∏á‡∏î‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà RAGAS ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤ RAG ‡∏ú‡∏¥‡∏î‡∏ï‡∏£‡∏á‡πÑ‡∏´‡∏ô (‡πÉ‡∏ä‡πâ debug)
    - ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡πÅ‡∏á‡πà framework ‡πÑ‡∏°‡πà‡∏ï‡∏¥‡∏î ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á embedding ‡∏ß‡∏±‡∏î similarity ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ embedding ‡πÑ‡∏ó‡∏¢‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô?
- **Questions:**
    - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô? ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á? ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏≠‡∏≤‡∏°‡∏≤?

## üîÆ Future Work / Ideas for Me

- _100% for framework_

# Zotero Notes


    # Annotations (1/5/2026, 10:25:30 PM)


        # Annotations
        (1/5/2026, 10:25:30 PM)


        ‚Äúreference-free‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúthere are several dimensions to consider‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúability of the retrieval system‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúability of the LLM‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúquality of the generation‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúwithout having to rely on ground truth human annotations‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúidea of using LLMs as knowledge bases‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúnot able to answer questions about events that have happened after they were trained‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äústruggle to memorise knowledge that is only rarely mentioned in the training corpus‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúinitial approaches relied on specialised LMs‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúsimply adding retrieved documents to the input of a standard LM can also work well‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúaffected by the retrieval model‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúor the prompt‚Äù (Shahul Es et al., 2025, p. 1)


        ‚ÄúAutomated evaluation‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúoften evaluated in terms of the language modelling task‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúnot always predictive‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúnot accessible for some closed models‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúwe present Ragas‚Äù (Shahul Es et al., 2025, p. 1)


        ‚Äúreference answers may not be available‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúan integration with both llama-index and Langchain‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúRelated Work‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúEstimating faithfulness using LLMs‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúexisting models struggle with detecting hallucination when using standard prompting strategies‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúlinking the generated responses to facts from an external knowledge base‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúprobabilities assigned to individual tokens‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúBARTScore‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúestimates factuality‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúwhether the answer is true or false‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúthe need to access the hidden states‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúunsuitable‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúSelfCheckGPT‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúsampling multiple answers‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúAutomated evaluation of text generation systems‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúevaluate other aspects‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúGPTScore‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúbased on the average probability‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúdirectly asks ChatGPT‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúbetween 0 and 100‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúof being sensitive to the design of the prompt‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúLLM to select the best answer among a number of candidates‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúthe order in which the answers is presented‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúthe availability of one or more reference answers‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúBERTScore‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúMoverScore‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúthe similarity between the generated answer and the reference answers‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúBARTScore‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúuses reference answers‚Äù (Shahul Es et al., 2025, p. 2)


        ‚ÄúEvaluation Strategies‚Äù (Shahul Es et al., 2025, p. 2)


        ‚Äúwe usually do not have access to human-annotated datasets or reference answers‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúfully self-contained‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúreference-free‚Äù (Shahul Es et al., 2025, p. 3)


        ‚ÄúFaithfulness‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúthe answer should be grounded in the given context‚Äù (Shahul Es et al., 2025, p. 3)


        ‚ÄúAnswer Relevance‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúgenerated answer should address the actual question‚Äù (Shahul Es et al., 2025, p. 3)


        ‚ÄúContext Relevance‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúretrieved context should be focused, containing as little irrelevant information as possible‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúassociated with feeding long context‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúlong‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúoften less effective‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúgpt-3.5-turbo-16k‚Äù (Shahul Es et al., 2025, p. 3)


        ‚ÄúFaithfulness‚Äù (Shahul Es et al., 2025, p. 3)


        ‚ÄúLLM to extract a set of statements‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúdecompose longer sentences‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúusing a verification function‚Äù (Shahul Es et al., 2025, p. 3)


        ‚ÄúAnswer relevance‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúprompt the LLM to generate n potential questions qi based on as(q),‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äútext-embedding-ada-002‚Äù (Shahul Es et al., 2025, p. 3)


        ‚ÄúContext relevance‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúpenalise the‚Äù (Shahul Es et al., 2025, p. 3)


        ‚Äúinclusion of redundant information‚Äù (Shahul Es et al., 2025, p. 4)


        ‚ÄúLLM extracts a subset of sentences, Sext, from c(q) that are crucial to answer q‚Äù (Shahul Es et al., 2025, p. 4)


        ‚ÄúThe WikiEval Dataset‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúcreated a new dataset, which we refer to as WikiEval‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúselected 50 Wikipedia pages‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúasked ChatGPT to suggest a question that can be answered based on the introductory section of the page‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúused ChatGPT to answer the generated question‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúquestions were annotated‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúby two annotators‚Äù (Shahul Es et al., 2025, p. 4)


        ‚ÄúFaithfulness‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúfirst used ChatGPT‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúwithout access‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äújudge which of the two answers was the most faithful‚Äù (Shahul Es et al., 2025, p. 4)


        ‚ÄúAnswer relevance‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúused ChatGPT to obtain candidate answers‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúindicate which of the two answers had the highest answer relevance‚Äù (Shahul Es et al., 2025, p. 4)


        ‚ÄúContext relevance‚Äù (Shahul Es et al., 2025, p. 4)


        ‚Äúfirst added additional sentences to the context by scraping back-links‚Äù (Shahul Es et al., 2025, p. 4)


        ‚ÄúExperiments‚Äù (Shahul Es et al., 2025, p. 5)


        ‚Äúcount how often the answer/context preferred by the model‚Äù (Shahul Es et al., 2025, p. 5)


        ‚Äúcoincides with the answer/context preferred by the human annotators‚Äù (Shahul Es et al., 2025, p. 5)


        ‚Äúterms of accuracy‚Äù (Shahul Es et al., 2025, p. 5)


        ‚ÄúGPT Score‚Äù (Shahul Es et al., 2025, p. 5)


        ‚Äúassign a score between 0 and 10‚Äù (Shahul Es et al., 2025, p. 5)


        ‚ÄúGPT Ranking‚Äù (Shahul Es et al., 2025, p. 5)


        ‚Äúasks ChatGPT to select the preferred answer/‚Äù (Shahul Es et al., 2025, p. 5)


        ‚Äúcontext‚Äù (Shahul Es et al., 2025, p. 5)


        ‚Äúmuch closer aligned with the human judgements‚Äù (Shahul Es et al., 2025, p. 5)


        ‚ÄúChatGPT often struggles with the task of selecting the sentences from the context that are crucia‚Äù (Shahul Es et al., 2025, p. 5)


        ‚ÄúConclusions‚Äù (Shahul Es et al., 2025, p. 5)


